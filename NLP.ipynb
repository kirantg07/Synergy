{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd8e34b7-fd16-4a70-ab05-a0f34f939234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/12.1 MB 14.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 18.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/12.1 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.1 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.9/12.1 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 20.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.1/12.1 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.4/12.1 MB 22.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.6/181.6 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 479.7/479.7 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.2/6.6 MB 37.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/6.6 MB 30.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.4/6.6 MB 27.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 24.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 23.5 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, cloudpathlib, catalogue, blis, typer, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8474e33e-5474-4cc6-97a7-2f257d9f2d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\jaide\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.1.4)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading pyFUME-0.3.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Collecting simpful (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Downloading pyFUME-0.3.1-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.6/59.6 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20451 sha256=a137275b3eb8ded163af3dc934d208b8d40ea569ca5a9c0615202dafecbcb670\n",
      "  Stored in directory: c:\\users\\jaide\\appdata\\local\\pip\\cache\\wheels\\69\\f5\\e5\\18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3517 sha256=84cf4c6f4cb4c2e64568192ce82d148da1ce556461666ce6340c0abd08b7d6a5\n",
      "  Stored in directory: c:\\users\\jaide\\appdata\\local\\pip\\cache\\wheels\\9d\\ff\\2f\\afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.3.1 simpful-2.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d5465b3-ec1a-4e1c-877e-26915307cda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.2\n",
      "  Downloading gensim-3.8.2.tar.gz (23.4 MB)\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/23.4 MB 487.6 kB/s eta 0:00:48\n",
      "     ---------------------------------------- 0.3/23.4 MB 2.0 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.9/23.4 MB 5.1 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.0/23.4 MB 5.5 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.0/23.4 MB 5.5 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.0/23.4 MB 5.5 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.0/23.4 MB 5.5 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.0/23.4 MB 5.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 1.6/23.4 MB 3.6 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 2.5/23.4 MB 5.0 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 5.9 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 3.9/23.4 MB 4.6 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 4.2/23.4 MB 4.9 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 4.2/23.4 MB 4.9 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 4.2/23.4 MB 4.3 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 4.7/23.4 MB 4.5 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 5.4/23.4 MB 5.0 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.9/23.4 MB 5.3 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.3/23.4 MB 5.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.3/23.4 MB 5.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.3/23.4 MB 5.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.4/23.4 MB 4.9 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 6.6/23.4 MB 5.0 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 7.1/23.4 MB 5.1 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 7.7/23.4 MB 5.4 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.4/23.4 MB 5.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.4/23.4 MB 5.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.4/23.4 MB 5.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.6/23.4 MB 5.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.3/23.4 MB 5.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 10.0/23.4 MB 5.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 10.8/23.4 MB 6.3 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.5/23.4 MB 7.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 11.5/23.4 MB 7.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 11.5/23.4 MB 7.3 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.0/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.8/23.4 MB 5.9 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.7/23.4 MB 6.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.4/23.4 MB 6.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.2/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 7.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.5/23.4 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.8/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 16.8/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 16.8/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 16.8/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 16.9/23.4 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 17.7/23.4 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.5/23.4 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.9/23.4 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.9/23.4 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.9/23.4 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.9/23.4 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.9/23.4 MB 6.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.4/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.4/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.5/23.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.9/23.4 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.0/23.4 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.1/23.4 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.6/23.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.2/23.4 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.4/23.4 MB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim==3.8.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim==3.8.2) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim==3.8.2) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gensim==3.8.2) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-3.8.2-cp311-cp311-win_amd64.whl size=23714549 sha256=57e6a3cf09b959e8aa025e9642ea9146c6bc58e96fcb18d56fe940a3e1145886\n",
      "  Stored in directory: c:\\users\\jaide\\appdata\\local\\pip\\cache\\wheels\\6b\\83\\66\\fa404002b2e8e6b07c71c082a1f1290afeee0e90c91fc0a828\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.0\n",
      "    Uninstalling gensim-4.3.0:\n",
      "      Successfully uninstalled gensim-4.3.0\n",
      "Successfully installed gensim-3.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"gensim==3.8.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43bf53b2-191f-4654-88a8-77457b22853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaide\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dc599f0-1b46-4809-9dfc-ede4e7d5afef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jaide\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56e09ebb-a6f0-4774-8836-2584cf207f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jaide\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dde7d744-429a-433d-8eb4-161460cd3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jaide\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "551fb9b5-06d0-4aff-9ef0-c3a5079e6b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Based on your provided example of a Transport App, here's a basic outline of how you can enrich user input and provide additional information:  User Input:  The user inputs details such as the mode of transportation (car, bike, auto), the distance to the destination, estimated time of travel, and any additional preferences (e.g., avoiding toll roads, specific departure time). Enrichment and Additional Information:  Mode of Transportation: Enrichment: If the user selects a car, the app could suggest alternative routes or parking availability. Additional Information: Provide information on fuel efficiency, estimated fuel cost, and potential environmental impact. Distance and Time: Enrichment: Factor in real-time traffic data to provide more accurate estimates of travel time. Additional Information: Offer suggestions for optimal departure times based on traffic patterns or provide alternate routes to avoid congestion. Traffic Density: Enrichment: Incorporate live traffic updates to suggest the least congested route. Additional Information: Provide insights on expected delays and offer alternate routes to minimize travel time. Cost Management: Enrichment: Offer cost comparisons between different transportation modes (e.g., car, bike, public transit). Additional Information: Provide information on toll charges, parking fees, and potential savings by choosing alternative transportation options. Output:  The enriched output could include a summary of the user's input along with additional insights and recommendations based on the selected mode of transportation, distance, time, traffic conditions, and cost considerations. For example: \"You've selected to travel by car for a distance of 20 kilometers. Based on current traffic conditions, the estimated travel time is 40 minutes. We recommend departing in 15 minutes to avoid heavy traffic on your route. Estimated fuel cost is $5, and parking availability at your destination is limited. Consider alternative transportation options for a quicker and more cost-effective journey.\" Continuous Improvement:  Collect feedback from users to improve the accuracy and relevance of the information provided. Incorporate machine learning algorithms to analyze user preferences and behavior, allowing the app to tailor recommendations more effectively over time. By following this approach, your Transport App can enrich user input with additional information and provide valuable insights to enhance the overall travel experience.\n"
     ]
    }
   ],
   "source": [
    "text = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e15f1cb-c681-40e3-94c9-4f84e9dceefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based prep 's AUX [on]\n",
      "on prep Based VERB [example]\n",
      "your poss example NOUN []\n",
      "provided amod example NOUN []\n",
      "example pobj on ADP [your, provided, of]\n",
      "of prep example NOUN [App]\n",
      "a det App PROPN []\n",
      "Transport compound App PROPN []\n",
      "App pobj of ADP [a, Transport]\n",
      ", punct 's AUX []\n",
      "here advmod 's AUX []\n",
      "'s ROOT 's AUX [Based, ,, here, outline, :, 1, .]\n",
      "a det outline NOUN []\n",
      "basic amod outline NOUN []\n",
      "outline nsubj 's AUX [a, basic, of]\n",
      "of prep outline NOUN [enrich]\n",
      "how advmod enrich VERB []\n",
      "you nsubj enrich VERB []\n",
      "can aux enrich VERB []\n",
      "enrich pcomp of ADP [how, you, can, input, and, provide]\n",
      "user compound input NOUN []\n",
      "input dobj enrich VERB [user]\n",
      "and cc enrich VERB []\n",
      "provide conj enrich VERB [information]\n",
      "additional amod information NOUN []\n",
      "information dobj provide VERB [additional]\n",
      ": punct 's AUX [\n",
      "          ]\n",
      "\n",
      "           dep : PUNCT []\n",
      "1 nsubj 's AUX []\n",
      ". punct 's AUX []\n",
      "User compound Input PROPN []\n",
      "Input ROOT Input PROPN [User, :, -]\n",
      ": punct Input PROPN [\n",
      "             ]\n",
      "\n",
      "              dep : PUNCT []\n",
      "- punct Input PROPN []\n",
      "The det user NOUN []\n",
      "user nsubj inputs VERB [The]\n",
      "inputs ROOT inputs VERB [user, details, ,, distance, .]\n",
      "details dobj inputs VERB [as]\n",
      "such amod as ADP []\n",
      "as prep details NOUN [such, mode]\n",
      "the det mode NOUN []\n",
      "mode pobj as ADP [the, of, )]\n",
      "of prep mode NOUN [transportation]\n",
      "transportation pobj of ADP [(, auto]\n",
      "( punct transportation NOUN []\n",
      "car nmod auto NOUN [,, bike]\n",
      ", punct car NOUN []\n",
      "bike conj car NOUN [,]\n",
      ", punct bike NOUN []\n",
      "auto appos transportation NOUN [car]\n",
      ") punct mode NOUN []\n",
      ", punct inputs VERB []\n",
      "the det distance NOUN []\n",
      "distance dobj inputs VERB [the, to, ,, time]\n",
      "to prep distance NOUN [destination]\n",
      "the det destination NOUN []\n",
      "destination pobj to ADP [the]\n",
      ", punct distance NOUN []\n",
      "estimated amod time NOUN []\n",
      "time appos distance NOUN [estimated, of, ,, and, preferences]\n",
      "of prep time NOUN [travel]\n",
      "travel pobj of ADP []\n",
      ", punct time NOUN []\n",
      "and cc time NOUN []\n",
      "any det preferences NOUN []\n",
      "additional amod preferences NOUN []\n",
      "preferences conj time NOUN [any, additional, (, e.g., ,, avoiding, )]\n",
      "( punct preferences NOUN []\n",
      "e.g. advmod preferences NOUN []\n",
      ", punct preferences NOUN []\n",
      "avoiding acl preferences NOUN [roads]\n",
      "toll compound roads NOUN []\n",
      "roads dobj avoiding VERB [toll, ,, time]\n",
      ", punct roads NOUN []\n",
      "specific amod time NOUN []\n",
      "departure compound time NOUN []\n",
      "time appos roads NOUN [specific, departure]\n",
      ") punct preferences NOUN []\n",
      ". punct inputs VERB [\n",
      "          ]\n",
      "\n",
      "           dep . PUNCT []\n",
      "2 ROOT 2 X [.]\n",
      ". punct 2 X []\n",
      "Enrichment dep Mode PROPN [and, Information]\n",
      "and cc Enrichment NOUN []\n",
      "Additional compound Information PROPN []\n",
      "Information conj Enrichment NOUN [Additional]\n",
      ": punct Mode PROPN [\n",
      "             ]\n",
      "\n",
      "              dep : PUNCT []\n",
      "- punct Mode PROPN []\n",
      "Mode dep Enrichment NOUN [Enrichment, :, -, of]\n",
      "of prep Mode PROPN [Transportation]\n",
      "Transportation pobj of ADP []\n",
      ": punct Enrichment NOUN [\n",
      "               ]\n",
      "\n",
      "                dep : PUNCT []\n",
      "- punct Enrichment NOUN []\n",
      "Enrichment dep suggest VERB [Mode, :, -]\n",
      ": punct suggest VERB []\n",
      "If mark selects VERB []\n",
      "the det user NOUN []\n",
      "user nsubj selects VERB [the]\n",
      "selects advcl suggest VERB [If, user, car]\n",
      "a det car NOUN []\n",
      "car dobj selects VERB [a]\n",
      ", punct suggest VERB []\n",
      "the det app NOUN []\n",
      "app nsubj suggest VERB [the]\n",
      "could aux suggest VERB []\n",
      "suggest ROOT suggest VERB [Enrichment, :, selects, ,, app, could, routes, .]\n",
      "alternative amod routes NOUN []\n",
      "routes dobj suggest VERB [alternative, or, availability]\n",
      "or cc routes NOUN []\n",
      "parking compound availability NOUN []\n",
      "availability conj routes NOUN [parking]\n",
      ". punct suggest VERB [\n",
      "               ]\n",
      "\n",
      "                dep . PUNCT []\n",
      "- punct Information NOUN []\n",
      "Additional amod Information NOUN []\n",
      "Information ROOT Information NOUN [-, Additional, :]\n",
      ": punct Information NOUN []\n",
      "Provide ROOT Provide VERB [information, ,, cost, .]\n",
      "information dobj Provide VERB [on]\n",
      "on prep information NOUN [efficiency]\n",
      "fuel compound efficiency NOUN []\n",
      "efficiency pobj on ADP [fuel]\n",
      ", punct Provide VERB []\n",
      "estimated amod cost NOUN []\n",
      "fuel compound cost NOUN []\n",
      "cost npadvmod Provide VERB [estimated, fuel, ,, and, impact]\n",
      ", punct cost NOUN []\n",
      "and cc cost NOUN []\n",
      "potential amod impact NOUN []\n",
      "environmental amod impact NOUN []\n",
      "impact conj cost NOUN [potential, environmental]\n",
      ". punct Provide VERB [\n",
      "          ]\n",
      "\n",
      "           dep . PUNCT []\n",
      "3 ROOT 3 X [.]\n",
      ". punct 3 X []\n",
      "Output ROOT Output NOUN [:, -]\n",
      ": punct Output NOUN [\n",
      "             ]\n",
      "\n",
      "              dep : PUNCT []\n",
      "- punct Output NOUN []\n",
      "The det output NOUN []\n",
      "enriched amod output NOUN []\n",
      "output nsubj include VERB [The, enriched]\n",
      "could aux include VERB []\n",
      "include ROOT include VERB [output, could, summary, along, .]\n",
      "a det summary NOUN []\n",
      "summary dobj include VERB [a, of]\n",
      "of prep summary NOUN [input]\n",
      "the det user NOUN []\n",
      "user poss input NOUN [the, 's]\n",
      "'s case user NOUN []\n",
      "input pobj of ADP [user]\n",
      "along prep include VERB [with]\n",
      "with prep along ADP [insights]\n",
      "additional amod insights NOUN []\n",
      "insights pobj with ADP [additional, and, recommendations, based]\n",
      "and cc insights NOUN []\n",
      "recommendations conj insights NOUN []\n",
      "based acl insights NOUN [on]\n",
      "on prep based VERB [mode]\n",
      "the det mode NOUN []\n",
      "selected amod mode NOUN []\n",
      "mode pobj on ADP [the, selected, of]\n",
      "of prep mode NOUN [transportation]\n",
      "transportation pobj of ADP [,, distance, ,, conditions]\n",
      ", punct transportation NOUN []\n",
      "distance conj transportation NOUN [,, time]\n",
      ", punct distance NOUN []\n",
      "time conj distance NOUN []\n",
      ", punct transportation NOUN []\n",
      "traffic compound conditions NOUN []\n",
      "conditions conj transportation NOUN [traffic, ,, and, considerations]\n",
      ", punct conditions NOUN []\n",
      "and cc conditions NOUN []\n",
      "cost compound considerations NOUN []\n",
      "considerations conj conditions NOUN [cost]\n",
      ". punct include VERB [\n",
      "          ]\n",
      "\n",
      "           dep . PUNCT []\n",
      "4 ROOT 4 X [.]\n",
      ". punct 4 X []\n",
      "Continuous compound Improvement PROPN []\n",
      "Improvement ROOT Improvement PROPN [Continuous, :, Collect, .]\n",
      ": punct Improvement PROPN [\n",
      "             ]\n",
      "\n",
      "              dep : PUNCT []\n",
      "- punct Collect VERB []\n",
      "Collect appos Improvement PROPN [-, feedback, improve]\n",
      "feedback dobj Collect VERB [from]\n",
      "from prep feedback NOUN [users]\n",
      "users pobj from ADP []\n",
      "to aux improve VERB []\n",
      "improve advcl Collect VERB [to, accuracy]\n",
      "the det accuracy NOUN []\n",
      "accuracy dobj improve VERB [the, and, relevance, of]\n",
      "and cc accuracy NOUN []\n",
      "relevance conj accuracy NOUN []\n",
      "of prep accuracy NOUN [information]\n",
      "the det information NOUN []\n",
      "information pobj of ADP [the, provided]\n",
      "provided acl information NOUN []\n",
      ". punct Improvement PROPN []\n",
      "Tokens: ['Based', 'on', 'your', 'provided', 'example', 'of', 'a', 'Transport', 'App', ',', 'here', \"'s\", 'a', 'basic', 'outline', 'of', 'how', 'you', 'can', 'enrich', 'user', 'input', 'and', 'provide', 'additional', 'information', ':', '1', '.', 'User', 'Input', ':', '-', 'The', 'user', 'inputs', 'details', 'such', 'as', 'the', 'mode', 'of', 'transportation', '(', 'car', ',', 'bike', ',', 'auto', ')', ',', 'the', 'distance', 'to', 'the', 'destination', ',', 'estimated', 'time', 'of', 'travel', ',', 'and', 'any', 'additional', 'preferences', '(', 'e.g.', ',', 'avoiding', 'toll', 'roads', ',', 'specific', 'departure', 'time', ')', '.', '2', '.', 'Enrichment', 'and', 'Additional', 'Information', ':', '-', 'Mode', 'of', 'Transportation', ':', '-', 'Enrichment', ':', 'If', 'the', 'user', 'selects', 'a', 'car', ',', 'the', 'app', 'could', 'suggest', 'alternative', 'routes', 'or', 'parking', 'availability', '.', '-', 'Additional', 'Information', ':', 'Provide', 'information', 'on', 'fuel', 'efficiency', ',', 'estimated', 'fuel', 'cost', ',', 'and', 'potential', 'environmental', 'impact', '.', '3', '.', 'Output', ':', '-', 'The', 'enriched', 'output', 'could', 'include', 'a', 'summary', 'of', 'the', 'user', \"'s\", 'input', 'along', 'with', 'additional', 'insights', 'and', 'recommendations', 'based', 'on', 'the', 'selected', 'mode', 'of', 'transportation', ',', 'distance', ',', 'time', ',', 'traffic', 'conditions', ',', 'and', 'cost', 'considerations', '.', '4', '.', 'Continuous', 'Improvement', ':', '-', 'Collect', 'feedback', 'from', 'users', 'to', 'improve', 'the', 'accuracy', 'and', 'relevance', 'of', 'the', 'information', 'provided', '.']\n",
      "Sentences: [\"Based on your provided example of a Transport App, here's a basic outline of how you can enrich user input and provide additional information:\\n          1.\", 'User Input:\\n             - The user inputs details such as the mode of transportation (car, bike, auto), the distance to the destination, estimated time of travel, and any additional preferences (e.g., avoiding toll roads, specific departure time).', '2.', 'Enrichment and Additional Information:\\n             - Mode of Transportation:\\n               - Enrichment: If the user selects a car, the app could suggest alternative routes or parking availability.', '- Additional Information: Provide information on fuel efficiency, estimated fuel cost, and potential environmental impact.', '3.', \"Output:\\n             - The enriched output could include a summary of the user's input along with additional insights and recommendations based on the selected mode of transportation, distance, time, traffic conditions, and cost considerations.\", '4.', 'Continuous Improvement:\\n             - Collect feedback from users to improve the accuracy and relevance of the information provided.']\n",
      "Filtered Tokens: ['Based', 'provided', 'example', 'Transport', 'App', ',', \"'s\", 'basic', 'outline', 'enrich', 'user', 'input', 'provide', 'additional', 'information', ':', '1', '.', 'User', 'Input', ':', '-', 'user', 'inputs', 'details', 'mode', 'transportation', '(', 'car', ',', 'bike', ',', 'auto', ')', ',', 'distance', 'destination', ',', 'estimated', 'time', 'travel', ',', 'additional', 'preferences', '(', 'e.g.', ',', 'avoiding', 'toll', 'roads', ',', 'specific', 'departure', 'time', ')', '.', '2', '.', 'Enrichment', 'Additional', 'Information', ':', '-', 'Mode', 'Transportation', ':', '-', 'Enrichment', ':', 'user', 'selects', 'car', ',', 'app', 'could', 'suggest', 'alternative', 'routes', 'parking', 'availability', '.', '-', 'Additional', 'Information', ':', 'Provide', 'information', 'fuel', 'efficiency', ',', 'estimated', 'fuel', 'cost', ',', 'potential', 'environmental', 'impact', '.', '3', '.', 'Output', ':', '-', 'enriched', 'output', 'could', 'include', 'summary', 'user', \"'s\", 'input', 'along', 'additional', 'insights', 'recommendations', 'based', 'selected', 'mode', 'transportation', ',', 'distance', ',', 'time', ',', 'traffic', 'conditions', ',', 'cost', 'considerations', '.', '4', '.', 'Continuous', 'Improvement', ':', '-', 'Collect', 'feedback', 'users', 'improve', 'accuracy', 'relevance', 'information', 'provided', '.']\n",
      "Lemmatized Tokens: ['Based', 'provided', 'example', 'Transport', 'App', ',', \"'s\", 'basic', 'outline', 'enrich', 'user', 'input', 'provide', 'additional', 'information', ':', '1', '.', 'User', 'Input', ':', '-', 'user', 'input', 'detail', 'mode', 'transportation', '(', 'car', ',', 'bike', ',', 'auto', ')', ',', 'distance', 'destination', ',', 'estimated', 'time', 'travel', ',', 'additional', 'preference', '(', 'e.g.', ',', 'avoiding', 'toll', 'road', ',', 'specific', 'departure', 'time', ')', '.', '2', '.', 'Enrichment', 'Additional', 'Information', ':', '-', 'Mode', 'Transportation', ':', '-', 'Enrichment', ':', 'user', 'selects', 'car', ',', 'app', 'could', 'suggest', 'alternative', 'route', 'parking', 'availability', '.', '-', 'Additional', 'Information', ':', 'Provide', 'information', 'fuel', 'efficiency', ',', 'estimated', 'fuel', 'cost', ',', 'potential', 'environmental', 'impact', '.', '3', '.', 'Output', ':', '-', 'enriched', 'output', 'could', 'include', 'summary', 'user', \"'s\", 'input', 'along', 'additional', 'insight', 'recommendation', 'based', 'selected', 'mode', 'transportation', ',', 'distance', ',', 'time', ',', 'traffic', 'condition', ',', 'cost', 'consideration', '.', '4', '.', 'Continuous', 'Improvement', ':', '-', 'Collect', 'feedback', 'user', 'improve', 'accuracy', 'relevance', 'information', 'provided', '.']\n",
      "Entities: [('a Transport App', 'PRODUCT'), ('1', 'CARDINAL'), ('2', 'CARDINAL'), ('Enrichment and Additional Information', 'ORG'), ('3', 'CARDINAL'), ('4', 'CARDINAL'), ('Continuous Improvement', 'PERSON')]\n",
      "Sentiment Score: {'neg': 0.016, 'neu': 0.928, 'pos': 0.056, 'compound': 0.7184}\n",
      "Summary: Based on your provided example of a Transport App, here's a basic outline of how you can enrich user input and provide additional information:\n",
      "          1.\n",
      "Keywords: [(',', 15), ('.', 9), ('the', 9), ('of', 8), (':', 8)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "\n",
    "# Text Parsing and Information Extraction\n",
    "def text_parsing_and_extraction(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Sentence Tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Stopword Removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    return tokens, sentences, filtered_tokens, lemmatized_tokens\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "def named_entity_recognition(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Sentiment Analysis\n",
    "def sentiment_analysis(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    return sentiment_score\n",
    "\n",
    "# Text Summarization\n",
    "def text_summarization(text, ratio=0.2):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = int(len(sentences) * ratio)\n",
    "    summary = \" \".join(sentences[:num_sentences])\n",
    "    return summary\n",
    "\n",
    "# Keyword Extraction\n",
    "def keyword_extraction(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    keywords = nltk.FreqDist(tokens)\n",
    "    return keywords.most_common(5)  # Return top 5 most common words as keywords\n",
    "\n",
    "# Dependency Parsing\n",
    "def dependency_parsing(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "              [child for child in token.children])\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"Based on your provided example of a Transport App, here's a basic outline of how you can enrich user input and provide additional information:\n",
    "          1. User Input:\n",
    "             - The user inputs details such as the mode of transportation (car, bike, auto), the distance to the destination, estimated time of travel, and any additional preferences (e.g., avoiding toll roads, specific departure time).\n",
    "          2. Enrichment and Additional Information:\n",
    "             - Mode of Transportation:\n",
    "               - Enrichment: If the user selects a car, the app could suggest alternative routes or parking availability.\n",
    "               - Additional Information: Provide information on fuel efficiency, estimated fuel cost, and potential environmental impact.\n",
    "          3. Output:\n",
    "             - The enriched output could include a summary of the user's input along with additional insights and recommendations based on the selected mode of transportation, distance, time, traffic conditions, and cost considerations.\n",
    "          4. Continuous Improvement:\n",
    "             - Collect feedback from users to improve the accuracy and relevance of the information provided.\"\"\"\n",
    "\n",
    "# Perform NLP tasks\n",
    "tokens, sentences, filtered_tokens, lemmatized_tokens = text_parsing_and_extraction(text)\n",
    "entities = named_entity_recognition(text)\n",
    "sentiment_score = sentiment_analysis(text)\n",
    "summary = text_summarization(text)\n",
    "keywords = keyword_extraction(text)\n",
    "dependency_parsing(text)\n",
    "\n",
    "# Print results\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Sentences:\", sentences)\n",
    "print(\"Filtered Tokens:\", filtered_tokens)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "print(\"Entities:\", entities)\n",
    "print(\"Sentiment Score:\", sentiment_score)\n",
    "print(\"Summary:\", summary)\n",
    "print(\"Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a47e7-445e-4a53-bf09-b758e91cf6e0",
   "metadata": {},
   "source": [
    "**NLP part Output Explaination**\n",
    "\n",
    "The output consists of several sections:\r\n",
    "\r\n",
    "Tokens, Sentences, Filtered Tokens, Lemmatized Tokens: These sections provide the breakdown of the text into individual tokens, sentences, filtered tokens (excluding stop words and punctuation), and lemmatized tokens (normalized form of words).\r\n",
    "\r\n",
    "Entities: This section identifies named entities in the text along with their respective entity types. In this case, it identifies \"a Transport App\" as a PRODUCT entity and numerical entities such as \"1\", \"2\", \"3\", and \"4\".\r\n",
    "\r\n",
    "Sentiment Score: This section provides the sentiment analysis score for the entire text. It includes values for negative, neutral, positive sentiments, and a compound score representing the overall sentiment.\r\n",
    "\r\n",
    "Summary: This section presents a summarized version of the text, condensing the main points and key information.\r\n",
    "\r\n",
    "Keywords: This section extracts keywords from the text along with their frequencies. It helps identify important terms that contribute to the overall meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb41b1-930a-44f8-8129-a2bf86573c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
